{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVWx1pIhGBSEUaY70aLZr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f341d8c8c1af426997042df71258087f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9dca79e073541f79643949a2f7f53dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d37af7a0fb44d9cbcc6d1250405d7fa",
              "IPY_MODEL_f96ba10473da4beebc61ff54386d2278"
            ]
          }
        },
        "a9dca79e073541f79643949a2f7f53dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d37af7a0fb44d9cbcc6d1250405d7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_7ed4935fb0ed4ff1a6fd575b6889dfa5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.52MB of 0.52MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c516d19e8d02416a9e4aa91c5e85f0ce"
          }
        },
        "f96ba10473da4beebc61ff54386d2278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e7377ea78b347aeb6aef5299c7c4de5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d0f6292fc9f4a8aa206d691be048df7"
          }
        },
        "7ed4935fb0ed4ff1a6fd575b6889dfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c516d19e8d02416a9e4aa91c5e85f0ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e7377ea78b347aeb6aef5299c7c4de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d0f6292fc9f4a8aa206d691be048df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karabhilash/CS6910-Fun_of_DL/blob/main/Assignment3/Assignment3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCrl0HxdTYbr"
      },
      "source": [
        "\n",
        "\n",
        "!pip install wandb\n",
        "\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "\n",
        "!tar -xf dakshina_dataset_v1.0.tar\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5sG-QCj1KyB",
        "outputId": "85da7882-94f1-4a82-8c9a-c932a71f6ec7"
      },
      "source": [
        "!ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dakshina_dataset_v1.0  dakshina_dataset_v1.0.tar  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RO1GyoB3e-O"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate,TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, GRU,SimpleRNN\n",
        "\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense,BatchNormalization\n",
        "from keras.layers import Flatten\n",
        "import math\n",
        "from keras.layers import Dropout\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkljF7Ay09Vo"
      },
      "source": [
        "train_file=\"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "val_file=\"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
        "test_file=\"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VokGP3VNdOu"
      },
      "source": [
        "train_data = pd.read_csv(train_file,sep='\\t',names=['target','src','occurances'])\n",
        "val_data = pd.read_csv(val_file,sep='\\t',names=['target','src','occurances'])\n",
        "test_data = pd.read_csv(test_file,sep='\\t',names=['target','src','occurances'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB4KPMWy0XwJ"
      },
      "source": [
        "def character_set(source,target):\n",
        "    s_char,t_char= set(),set()\n",
        "    for s in source:\n",
        "        for ch in s:\n",
        "            s_char.add(ch)\n",
        "    for s in target:\n",
        "        for ch in s:\n",
        "            t_char.add(ch)\n",
        "    s_char.add(\" \")\n",
        "    t_char.add(\" \")\n",
        "    return sorted(list(s_char)),sorted(list(t_char))\n",
        "\n",
        "def create_lookup(tokens):\n",
        "    stoi = dict(zip(tokens,range(len(tokens))))\n",
        "    itos = {v: k for k, v in stoi.items()}\n",
        "    return stoi,itos\n",
        "\n",
        "def encode(source,target,source_lex,target_lex,source_stoi,target_stoi):\n",
        "\n",
        "    num_source_tokens = len(source_lex)\n",
        "    num_target_tokens = len(target_lex)\n",
        "    max_source_length = max([len(s) for s in source])\n",
        "    max_target_length = max([len(s) for s in target])\n",
        "    num_samples = len(source)\n",
        "\n",
        "    encoder_input= np.zeros((num_samples,max_source_length,num_source_tokens))\n",
        "    decoder_input=np.zeros((num_samples,max_target_length,num_target_tokens))\n",
        "    decoder_target=np.zeros((num_samples,max_target_length,num_target_tokens))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        for j,char in enumerate(source[i]):\n",
        "            encoder_input[i,j,source_stoi[char]] = 1.0\n",
        "        encoder_input[i,j+1:,source_stoi[\" \"]] = 1.0\n",
        "        for j,char in enumerate(target[i]):\n",
        "            decoder_input[i,j,target_stoi[char]] = 1.0\n",
        "        decoder_input[i,j+1:,target_stoi[\" \"]] = 1.0\n",
        "        for j,char in enumerate(target[i][1:]):\n",
        "            decoder_target[i,j-1,target_stoi[char]] = 1.0\n",
        "        decoder_target[i,j:,target_stoi[\" \"]] = 1.0\n",
        "    return encoder_input,decoder_input,decoder_target\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lRuQ2ybtDCv"
      },
      "source": [
        "source = [str(s) for s in list(train_data[\"src\"])]\n",
        "target = [str(s) for s in list(train_data[\"target\"])]\n",
        "target = [\"\\t\"+s+\"\\n\" for s in target]\n",
        "source_tokens,target_tokens = character_set(source,target)\n",
        "\n",
        "source_stoi,source_itos = create_lookup(source_tokens)\n",
        "target_stoi,target_itos = create_lookup(target_tokens)\n",
        "\n",
        "train_encoder_input,train_decoder_input,train_decoder_target = encode(source,target,source_tokens,target_tokens,source_stoi,target_stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXYrvAA_CzEp"
      },
      "source": [
        "\n",
        "max_source_length = max([len(s) for s in source])\n",
        "max_target_length = max([len(s) for s in target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFAAzBg4wwGe"
      },
      "source": [
        "#preprocess val data\n",
        "source_val = [str(s) for s in list(val_data[\"src\"])]\n",
        "target_val = [str(s) for s in list(val_data[\"target\"])]\n",
        "target_val = [\"\\t\"+s+\"\\n\" for s in target_val]\n",
        "val_encoder_input,val_decoder_input,val_decoder_target = encode(source_val,target_val,source_tokens,target_tokens,source_stoi,target_stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2LPLn8Twy_Y"
      },
      "source": [
        "#preprocess test data\n",
        "source_test = [str(s) for s in list(test_data[\"src\"])]\n",
        "target_test = [str(s) for s in list(test_data[\"target\"])]\n",
        "target_test = [\"\\t\"+s+\"\\n\" for s in target_test]\n",
        "test_encoder_input,test_decoder_input,test_decoder_target = encode(source_test,target_test,source_tokens,target_tokens,source_stoi,target_stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXQqUpndvkWv"
      },
      "source": [
        "def build_model_singleLink(cell_type,Dimensions,num_encoders,num_decoders,num_dense_neurons,dropout,extra_dense_layer,source_stoi,target_stoi):\n",
        "    num_encoder_tokens = len(source_stoi)\n",
        "    num_decoder_tokens = len(target_stoi)\n",
        "    \n",
        "    if cell_type=='RNN':\n",
        "        encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
        "        encoder_i = encoder_inputs\n",
        "        encoder_states=[]\n",
        "        for i in range(num_encoders):\n",
        "            encoder_i,state = SimpleRNN(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"enc_\"+str(i))(encoder_i)\n",
        "            encoder_states += [state]\n",
        "        encoder_output  = encoder_i\n",
        "\n",
        "        decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "        decoder_i = decoder_inputs\n",
        "\n",
        "        for i in range(num_decoders):\n",
        "            decoder_i,state = SimpleRNN(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"dec_\"+str(i))(decoder_i,initial_state=encoder_states[-1])\n",
        "        \n",
        "        decoder_output = decoder_i\n",
        "        if extra_dense_layer == True:\n",
        "            decoder_output = Dense(num_dense_neurons,activation='relu',name='dense')(decoder_output)\n",
        "        decoder_output = Dense(num_decoder_tokens,activation='softmax', name = 'final')(decoder_output)\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "\n",
        "    if cell_type=='GRU':\n",
        "        encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
        "        encoder_i = encoder_inputs\n",
        "        encoder_states=[]\n",
        "        for i in range(num_encoders):\n",
        "            encoder_i,state = GRU(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"enc_\"+str(i))(encoder_i)\n",
        "            encoder_states += [state]\n",
        "        encoder_output  = encoder_i\n",
        "\n",
        "        decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "        decoder_i = decoder_inputs\n",
        "\n",
        "        for i in range(num_decoders):\n",
        "            decoder_i,state = GRU(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"dec_\"+str(i))(decoder_i,initial_state=encoder_states[-1])\n",
        "        \n",
        "        decoder_output = decoder_i\n",
        "        if extra_dense_layer == True:\n",
        "            decoder_output = Dense(num_dense_neurons,activation='relu',name='dense')(decoder_output)\n",
        "        decoder_output = Dense(num_decoder_tokens,activation='softmax', name = 'final')(decoder_output)\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "        \n",
        "\n",
        "    if cell_type=='LSTM':\n",
        "        encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
        "        encoder_i = encoder_inputs\n",
        "        encoder_states=[]\n",
        "        for i in range(num_encoders):\n",
        "            encoder_i,s1,s2 = LSTM(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"enc_\"+str(i))(encoder_i)\n",
        "            encoder_states += [[s1,s2]]\n",
        "        encoder_output  = encoder_i\n",
        "\n",
        "        decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "        decoder_i = decoder_inputs\n",
        "\n",
        "        for i in range(num_decoders):\n",
        "            decoder_i,s1,s2 = LSTM(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"dec_\"+str(i))(decoder_i,initial_state=encoder_states[-1])\n",
        "        \n",
        "        decoder_output = decoder_i\n",
        "        if extra_dense_layer == True:\n",
        "            decoder_output = Dense(num_dense_neurons,activation='relu',name='dense')(decoder_output)\n",
        "        decoder_output = Dense(num_decoder_tokens,activation='softmax', name = 'final')(decoder_output)\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "        \n",
        "def build_model(cell_type,Dimensions,num_encoders,num_decoders,num_dense_neurons,dropout,extra_dense_layer,source_stoi,target_stoi):\n",
        "    num_encoder_tokens = len(source_stoi)\n",
        "    num_decoder_tokens = len(target_stoi)\n",
        "    \n",
        "    if cell_type=='RNN':\n",
        "        encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
        "        encoder_i = encoder_inputs\n",
        "        encoder_states=[]\n",
        "        for i in range(num_encoders):\n",
        "            encoder_i,state = SimpleRNN(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"enc_\"+str(i))(encoder_i)\n",
        "            encoder_states += [state]\n",
        "        encoder_output  = encoder_i\n",
        "\n",
        "        decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "        decoder_i = decoder_inputs\n",
        "\n",
        "        for i in range(num_decoders):\n",
        "            decoder_i,state = SimpleRNN(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"dec_\"+str(i))(decoder_i,initial_state=encoder_states[i])\n",
        "        \n",
        "        decoder_output = decoder_i\n",
        "        if extra_dense_layer == True:\n",
        "            decoder_output = Dense(num_dense_neurons,activation='relu',name='dense')(decoder_output)\n",
        "        decoder_output = Dense(num_decoder_tokens,activation='softmax', name = 'final')(decoder_output)\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "\n",
        "    if cell_type=='GRU':\n",
        "        encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
        "        encoder_i = encoder_inputs\n",
        "        encoder_states=[]\n",
        "        for i in range(num_encoders):\n",
        "            encoder_i,state = GRU(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"enc_\"+str(i))(encoder_i)\n",
        "            encoder_states += [state]\n",
        "        encoder_output  = encoder_i\n",
        "\n",
        "        decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "        decoder_i = decoder_inputs\n",
        "\n",
        "        for i in range(num_decoders):\n",
        "            decoder_i,state = GRU(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"dec_\"+str(i))(decoder_i,initial_state=encoder_states[i])\n",
        "        \n",
        "        decoder_output = decoder_i\n",
        "        if extra_dense_layer == True:\n",
        "            decoder_output = Dense(num_dense_neurons,activation='relu',name='dense')(decoder_output)\n",
        "        decoder_output = Dense(num_decoder_tokens,activation='softmax', name = 'final')(decoder_output)\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "        \n",
        "\n",
        "    if cell_type=='LSTM':\n",
        "        encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
        "        encoder_i = encoder_inputs\n",
        "        encoder_states=[]\n",
        "        for i in range(num_encoders):\n",
        "            encoder_i,s1,s2 = LSTM(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"enc_\"+str(i))(encoder_i)\n",
        "            encoder_states += [[s1,s2]]\n",
        "        encoder_output  = encoder_i\n",
        "\n",
        "        decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "        decoder_i = decoder_inputs\n",
        "\n",
        "        for i in range(num_decoders):\n",
        "            decoder_i,s1,s2 = LSTM(Dimensions,return_state=True,return_sequences=True,dropout=dropout,name= \"dec_\"+str(i))(decoder_i,initial_state=encoder_states[i])\n",
        "        \n",
        "        decoder_output = decoder_i\n",
        "        if extra_dense_layer == True:\n",
        "            decoder_output = Dense(num_dense_neurons,activation='relu',name='dense')(decoder_output)\n",
        "        decoder_output = Dense(num_decoder_tokens,activation='softmax', name = 'final')(decoder_output)\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp6XZAmhWhmT"
      },
      "source": [
        "def train_simple():\n",
        "    model = build_model(\"RNN\",256,3,3,64,0.3,False,source_stoi,target_stoi)\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "    model.fit([train_encoder_input,train_decoder_input],train_decoder_target,validation_data=([val_encoder_input,val_decoder_input],val_decoder_target) ,epochs = 3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p086B_yJni4M"
      },
      "source": [
        "train_simple()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_zYFnG63pcV"
      },
      "source": [
        "best_model = None\n",
        "best_val_acc = 0.0\n",
        "best_CONFIG = None\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "def paramTuning():\n",
        "    global best_model,best_val_acc,best_CONFIG\n",
        "    config = dict(\n",
        "        cell = \"LSTM\",\n",
        "        num_dense_neurons = 128,\n",
        "        dimensions= 256,\n",
        "        num_encoder_layers = 1,\n",
        "        num_decoder_layers = 1,\n",
        "        dropout = 0.3,\n",
        "        epochs = 2,\n",
        "        extra_dense_layer = False,\n",
        "        build_model_type = False\n",
        "    )\n",
        "\n",
        "    wandb.init(config=config)\n",
        "    CONFIG = wandb.config\n",
        "    if CONFIG.build_model_type:\n",
        "        model = build_model(CONFIG.cell,CONFIG.dimensions,CONFIG.num_encoder_layers,CONFIG.num_encoder_layers,CONFIG.num_dense_neurons,CONFIG.dropout,CONFIG.extra_dense_layer,source_stoi,target_stoi)\n",
        "    else:\n",
        "        model = build_model_singleLink(CONFIG.cell,CONFIG.dimensions,CONFIG.num_encoder_layers,CONFIG.num_decoder_layers,CONFIG.num_dense_neurons,CONFIG.dropout,CONFIG.extra_dense_layer,source_stoi,target_stoi)\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "    h = model.fit([train_encoder_input,train_decoder_input],train_decoder_target,validation_data=([val_encoder_input,val_decoder_input],val_decoder_target),epochs = CONFIG.epochs ,callbacks=[WandbCallback()])\n",
        "    print(h.history['val_accuracy'][-1])\n",
        "    if h.history['val_accuracy'][-1] > best_val_acc:\n",
        "        best_model = model\n",
        "        best_val_acc=h.history['val_accuracy'][-1]\n",
        "        best_CONFIG = CONFIG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "wKhRUwQ9OsZU",
        "outputId": "568e2b75-df1a-4c63-f5b8-b3e54e92d627"
      },
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"non-attention\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \n",
        "        \"cell\": \n",
        "            {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n",
        "        \n",
        "        \"dimensions\": \n",
        "            {\"values\": [256, 128, 64]},\n",
        "        \n",
        "        \"extra_dense_layer\": \n",
        "            {\"values\": [True,False]},\n",
        "        \n",
        "        \"optimiser\": \n",
        "            {\"values\": [\"rmsprop\", \"adam\"]},\n",
        "        \n",
        "        \"num_encoder_layers\": \n",
        "            {\"values\": [1, 2, 3]},\n",
        "        \n",
        "        \"num_decoder_layers\": \n",
        "            {\"values\": [1, 2, 3]},\n",
        "        \n",
        "        \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n",
        "        \n",
        "        \"epochs\": {\"values\": [5,10]},\n",
        "        \n",
        "        \"batch_size\": {\"values\": [32, 64]},\n",
        "        \"build_model_type\":\n",
        "            {'values':[True,False]} # if True,ith decoder layers initial state corresponds to ith encoder layer output state\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910-Assignment-3-1\",entity='abhilash-kar0')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 5ycfhsjc\n",
            "Sweep URL: https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/sweeps/5ycfhsjc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGgoKN4gUYD2"
      },
      "source": [
        "a='7206be0b2a6d421b3fa0fe354acc489584df6053'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f341d8c8c1af426997042df71258087f",
            "a9dca79e073541f79643949a2f7f53dc",
            "6d37af7a0fb44d9cbcc6d1250405d7fa",
            "f96ba10473da4beebc61ff54386d2278",
            "7ed4935fb0ed4ff1a6fd575b6889dfa5",
            "c516d19e8d02416a9e4aa91c5e85f0ce",
            "7e7377ea78b347aeb6aef5299c7c4de5",
            "9d0f6292fc9f4a8aa206d691be048df7"
          ]
        },
        "id": "905QyxUaUKG9",
        "outputId": "d3d659f5-1f99-4e2c-b6e0-4ee9123502a7"
      },
      "source": [
        "wandb.agent(sweep_id, paramTuning, count = 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: as6muu0y with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuild_model_type: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdimensions: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_dense_layer: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.32<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">fast-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1\" target=\"_blank\">https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/sweeps/5ycfhsjc\" target=\"_blank\">https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/sweeps/5ycfhsjc</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/runs/as6muu0y\" target=\"_blank\">https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/runs/as6muu0y</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210629_182024-as6muu0y</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 66)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_0 (SimpleRNN)               [(None, None, 64), ( 5888        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dec_0 (SimpleRNN)               [(None, None, 64), ( 8384        input_2[0][0]                    \n",
            "                                                                 enc_0[0][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "dec_1 (SimpleRNN)               [(None, None, 64), ( 8256        dec_0[0][0]                      \n",
            "                                                                 enc_0[0][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    8320        dec_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 66)     8514        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 39,362\n",
            "Trainable params: 39,362\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "1382/1382 [==============================] - 112s 79ms/step - loss: 6.1730 - accuracy: 0.7152 - val_loss: 45.6249 - val_accuracy: 0.6662\n",
            "Epoch 2/5\n",
            "1382/1382 [==============================] - 106s 77ms/step - loss: 39.7999 - accuracy: 0.7253 - val_loss: 84.1005 - val_accuracy: 0.6590\n",
            "Epoch 3/5\n",
            "1382/1382 [==============================] - 107s 77ms/step - loss: 65.8352 - accuracy: 0.7107 - val_loss: 106.2236 - val_accuracy: 0.6533\n",
            "Epoch 4/5\n",
            "1382/1382 [==============================] - 106s 77ms/step - loss: 72.7562 - accuracy: 0.7089 - val_loss: 149.0626 - val_accuracy: 0.6627\n",
            "Epoch 5/5\n",
            "1382/1382 [==============================] - 106s 77ms/step - loss: 115.3972 - accuracy: 0.7111 - val_loss: 199.7905 - val_accuracy: 0.6436\n",
            "0.643643856048584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 638<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f341d8c8c1af426997042df71258087f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.36MB of 0.36MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210629_182024-as6muu0y/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210629_182024-as6muu0y/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>121.56987</td></tr><tr><td>accuracy</td><td>0.71035</td></tr><tr><td>val_loss</td><td>199.79053</td></tr><tr><td>val_accuracy</td><td>0.64364</td></tr><tr><td>_runtime</td><td>543</td></tr><tr><td>_timestamp</td><td>1624991367</td></tr><tr><td>_step</td><td>4</td></tr><tr><td>best_val_loss</td><td>45.62489</td></tr><tr><td>best_epoch</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>▁▃▅▅█</td></tr><tr><td>accuracy</td><td>█▆▁▂▂</td></tr><tr><td>val_loss</td><td>▁▃▄▆█</td></tr><tr><td>val_accuracy</td><td>█▆▄▇▁</td></tr><tr><td>_runtime</td><td>▁▃▅▆█</td></tr><tr><td>_timestamp</td><td>▁▃▅▆█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">fast-sweep-4</strong>: <a href=\"https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/runs/as6muu0y\" target=\"_blank\">https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/runs/as6muu0y</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run as6muu0y errored: TypeError(\"'>' not supported between instances of 'float' and 'list'\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bu27udhu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuild_model_type: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdimensions: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_dense_layer: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.32<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">quiet-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1\" target=\"_blank\">https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/sweeps/5ycfhsjc\" target=\"_blank\">https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/sweeps/5ycfhsjc</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/runs/bu27udhu\" target=\"_blank\">https://wandb.ai/abhilash-kar0/CS6910-Assignment-3-1/runs/bu27udhu</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210629_183002-bu27udhu</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 66)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_0 (GRU)                     [(None, None, 256),  218880      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dec_0 (GRU)                     [(None, None, 256),  248832      input_2[0][0]                    \n",
            "                                                                 enc_0[0][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "enc_1 (GRU)                     [(None, None, 256),  394752      enc_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dec_1 (GRU)                     [(None, None, 256),  394752      dec_0[0][0]                      \n",
            "                                                                 enc_1[0][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dec_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 66)     8514        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,298,626\n",
            "Trainable params: 1,298,626\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "1241/1382 [=========================>....] - ETA: 5s - loss: 14.8234 - accuracy: 0.7266"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJKMmI6xe7vO"
      },
      "source": [
        "num_dec_layers=best_CONFIG.num_decoder_layers\n",
        "num_enc_layers=best_CONFIG.num_encoder_layers\n",
        "if best_CONFIG.build_model_type:\n",
        "    num_dec_layers=best_CONFIG.num_encoder_layers\n",
        "dim = best_CONFIG.dimensions\n",
        "model = best_model\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "\n",
        "encoder_states = []\n",
        "for i in range(num_enc_layers):\n",
        "    en_res = model.get_layer('enc_'+str(i)).output  \n",
        "    encoder_outputs = en_res[0] \n",
        "    encoder_states += [en_res[1:]]\n",
        "    \n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_i = decoder_inputs\n",
        "decoder_states_inputs = []\n",
        "decoder_states = []\n",
        "\n",
        "for i in range(num_dec_layers):\n",
        "    if best_CONFIG.cell == 'LSTM':\n",
        "        decoder_state_input_h = Input(shape=(dim,))\n",
        "        decoder_state_input_c = Input(shape=(dim,))\n",
        "        decoder_states_inputs += [decoder_state_input_h, decoder_state_input_c]\n",
        "    elif best_CONFIG.cell == 'GRU':\n",
        "        decoder_states_inputs += [Input(shape=(dim,))]\n",
        "    elif best_CONFIG.cell == 'RNN':\n",
        "        decoder_states_inputs += [Input(shape=(dim,))]\n",
        "    \n",
        "    \n",
        "    de_out = model.get_layer('dec_'+str(i))(decoder_i, initial_state=decoder_states_inputs[-1])\n",
        "    decoder_i = de_out[0]\n",
        "    decoder_states += [de_out[1:]]\n",
        "    \n",
        "decoder_outputs = decoder_i\n",
        "if best_CONFIG.extra_dense_layer:\n",
        "    decoder_outputs = model.get_layer('dense')(decoder_outputs)\n",
        "decoder_dense = model.get_layer('dense_1')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BYXIPSRKV6I"
      },
      "source": [
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, len(target_tokens)))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_stoi[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        outputs = decoder_model.predict([target_seq] + states_value)\n",
        "        output_tokens, states_value = outputs[0], outputs[1:]\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_itos[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_target_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, len(target_tokens)))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "#         states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCZhJ-OBHtN-",
        "outputId": "1eeef564-e3d2-4752-9938-52e5b992de9c"
      },
      "source": [
        "encoder_model.summary(),decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 27)]        0         \n",
            "_________________________________________________________________\n",
            "enc_0 (GRU)                  [(None, None, 256), (None 218880    \n",
            "_________________________________________________________________\n",
            "enc_1 (GRU)                  [(None, None, 256), (None 394752    \n",
            "=================================================================\n",
            "Total params: 613,632\n",
            "Trainable params: 613,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 66)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_0 (GRU)                     [(None, None, 256),  248832      input_2[0][0]                    \n",
            "                                                                 input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_1 (GRU)                     [(None, None, 256),  394752      dec_0[7][0]                      \n",
            "                                                                 input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dec_1[5][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 66)     8514        dense[4][0]                      \n",
            "==================================================================================================\n",
            "Total params: 684,994\n",
            "Trainable params: 684,994\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buFXiywmPYNx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}